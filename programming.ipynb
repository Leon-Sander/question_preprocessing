{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "8ac587500089045bda0d8680467a78b2a5f7abf79b6086e96a7d36f8c178cf35"
   }
  },
  "interpreter": {
   "hash": "8ac587500089045bda0d8680467a78b2a5f7abf79b6086e96a7d36f8c178cf35"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Question Classification into Types 1-4"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import re\n",
    "ir_single = [\"What are the main contributions of paper X?\",\n",
    "\"Which baselines were used in the paper X?\",\n",
    "\"Which dataset is used in the paper ‘On Emerging Entity Detection’?\",\n",
    "\"Does paper X provide a dataset?\",\n",
    "\"What machine learning methods does paper X compare?\", # die ersten 4 auch für IR global bloß im Plural halt\n",
    "\"Which datasets are mentioned in the paper X?\",\n",
    "\"Which datasets are compared to, in the paper ‘unarXive: A Large...’?\"]\n",
    "\n",
    "ir_single_pattern = [\"What (are|is|were) the (main )?contribution(s)? of paper .*\",\n",
    "                     \"Which .* (were|are|is) used in the paper .*\",\n",
    "                     \"Does paper .* provide a .*\",\n",
    "                     \"(What|Which) machine learning method(s)? does paper .* compare(\\?)?\",\n",
    "                     \"(Which|What) data( )?set(s)? (are|is) mentioned in the paper .*\",\n",
    "                     \"(Which|What) data( )?set(s)? (are|is) compared to .* in the paper .*\"]\n",
    "\n",
    "\n",
    "ir_global = [\"How good (BLUE score) is the best state-of-the-art model for machine translation?\",\n",
    "\"How large are the language models in GB published since 2011?\",\n",
    "\"Which use cases exist for cross-lingual scientific impact quantification?\",\n",
    "\"Which ML methods have been used by author Y?\",\n",
    "\"Which data sets have been introduced in papers at conference Z?\",\n",
    "\"Which ML methods have been used for annotating datasets in papers?\",\n",
    "\"What is proposed as future work regarding citation recommendation?\",\n",
    "\"Which metrics are used for evaluating scholarly trend detection approaches?\",\n",
    "\"Which datasets are mentioned in the papers ‘On Emerging Entity Detection’ and/or ‘Semantic Search for Novel Information’?\",\n",
    "\"Which datasets are considered for use in the papers ‘A Large-Scale Analysis of Cross-lingual Citations in English Papers’ and/or ‘Bootstrapping Multilingual Metadata Extraction: A Showcase in Cyrillic’?\",\n",
    "\"Which evaluation data sets are mentioned/used in the context of citation recommendation?\",\n",
    "\"Which methods are proposed for context-aware citation recommendation?\",\n",
    "\"Which datasets are used in the papers ‘On Emerging Entity Detection’ and/or ‘Semantic Search for Novel Information’?\",\n",
    "\"Which datasets are used in the evaluations regarding document embedding (in all papers)?\",\n",
    "\"Which datasets appear in the evaluations...\"\n",
    "]\n",
    "\n",
    "ir_global_pattern = [\"How .* are the .* models (in .* )?published since \\d+\\??\", #mglw zu offen\n",
    "                     \"Which use cases exist for .*\",\n",
    "                     \"Which (ML |.* )?methods have been used by author .*\\??\",\n",
    "                     \"Which data()?set(s)? (have been|were) introduced in (the )?papers .*( at conference .*\\??)?\",\n",
    "                     \"Which (ML |.* )?method(s)? (have been|were|are) used for .* data()?sets in papers?\",\n",
    "                     \"What (is|was) proposed as future work regarding .*\",\n",
    "                     \"Which metric(s)? (are|were|is) used for .*\",\n",
    "                     \"(Which|What) data()?set(s)? (are|is|were) mentioned in the papers .*\",\n",
    "                     \"(Which|What) data()?set(s)? (are|is|were) considered for (the )?use in the papers .*\",\n",
    "                     \"(Which|What) evaluation data sets are mentioned/used in the context of citation recommendation?\",\n",
    "                     \"(Which|What) method(s)? (were|are) proposed for .*\",\n",
    "                     \"(Which|What) data( )?set(s)? (are|is|were) used in the papers .*\",\n",
    "                     \"(Which|What) data( )?set(s)? (are|is|were) used in the evaluations regarding .*\",\n",
    "                     \"(Which|What) data( )?set(s)? (do )?appear in the .*\"\n",
    "                     ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kg_single = [\"Which papers does the paper X cite?\",\n",
    "\"When was the paper X published?\",\n",
    "\"Who authored paper X?\"]\n",
    "\n",
    "kg_single_pattern = [\"Which papers (is|does) the paper .* (cite|citing)\\?\",\n",
    "                     \"When was the paper .* published\\?\",\n",
    "                     \"Who authored paper .*\",\n",
    "                     \"Who (was|were) the author(s)? of the paper .*\"]\n",
    "\n",
    "kg_global = [\"Which papers are associated with BERT?\",\n",
    "\"Which conferences since 2011 have been most influential?\",\n",
    "\"How many papers have been published by KIT-AIFB in ISWC or ESWC since 2012?\",\n",
    "\"In which conferences has [M. Färber at KIT] published?\",\n",
    "]\n",
    "\n",
    "#Für Datum \n",
    "#14-11-2017\n",
    "#14.11.2017\n",
    "#14|11|2017\n",
    "#2017\n",
    "#((^([1-9] |1[0-9]| 2[0-9]|3[0-1])(.|-)([1-9] |1[0-2])(.|-|)(19|20)[0-9][0-9]$)|\\d+)\n",
    "\n",
    "kg_global_pattern = [\"(Which|What) papers (were|are) associated with .*\",\n",
    "                     \"(Which|What) conferences since ((^([1-9] |1[0-9]| 2[0-9]|3[0-1])(.|-)([1-9] |1[0-2])(.|-|)(19|20)[0-9][0-9]$)|\\d+) (have been|were|are) most influential?\",\n",
    "                     \"How many papers (have been|are|were) published .*\",\n",
    "                     \"In (which|what) conferences has .* published?\"]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "##### IMRAD classification\n",
    "# Which/What ... used/proposed/plan\n",
    "imrad = [\"(Which|What) (data( )?set(s)?|.*method(s)?|metric(s)?) (are|is|were|have been) (used|proposed|employed|utilised|utilized|applied|provided|introduced) .*\",\n",
    "        \"Does paper .* provide (a )?(data( )?set(s)?|.*method(s)?)\\??\",\n",
    "        \"Is paper .* (providing|using|proposing|utilising|utilizing) a data( )?set\\??\",\n",
    "        \"(Which|What) (data( )?set(s)?|.*method(s)?) does paper .* (compare|use|provide|employ)\",\n",
    "        \"(Which|What) (data( )?set(s)?|.*method(s)?) (are|is|was|were) compared to, in the paper .*\",\n",
    "        \"What (is|was|has been) proposed as future work .*\"\n",
    "    ]\n",
    "#“Does paper X provide a dataset?”,\n",
    "#“What machine learning methods does paper X compare?” \n",
    "#“Which datasets are compared to, in the paper ‘unarXive: A Large...’?”\n",
    "#“Which ML methods have been used by author Y?”\n",
    "#“Which data sets have been introduced in papers at conference Z?”\n",
    "#“Which ML methods have been used for annotating datasets in papers?”\n",
    "#“What is proposed as future work regarding citation recommendation?”\n",
    "#“Which metrics are used for evaluating scholarly trend detection approaches?”\n",
    "#“Which datasets are used in the papers ‘On Emerging Entity Detection’ and/or ‘Semantic Search for Novel Information’?”\n",
    "#“Which datasets are used in the evaluations regarding document embedding (in all papers)?”\n",
    "#“Which datasets appear in the evaluations...”\n",
    "#→ paraphrase questions...\n",
    "#→ filter by keywords (e.g., “use”); use WordNet for synonyms.\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from question_preprocessing import question_preprocessing\n",
    "qp = question_preprocessing()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "qp.check_imrad(\"What machine learning methods have been proposed in the conference for test?\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import re\n",
    "annotation_templates = [\"((data( )?set(s)?)|(.*method(s)?))\"]\n",
    "test = \"What datasets have been proposed in the conference for test?\"\n",
    "test2 = \"nope\"\n",
    "for tmp in annotation_templates:\n",
    "    if re.findall(tmp, test) != None:\n",
    "        print(re.findall(tmp, test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('datasets', 'datasets', '', 's', '', '')]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "if re.search(annotation_templates[0], test2) == None:\n",
    "    print(\"none\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "none\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "##### Dataset Creation for BERT Classifier\n",
    "#### kg single\n",
    "\n",
    "\n",
    "### kg global\n",
    "x = \"test\"\n",
    "thema = \"test\"\n",
    "date = \"2009\"\n",
    "name = \"test\"\n",
    "conference = \"test\"\n",
    "\n",
    "[\n",
    "\"Which papers were associated with %s\" % (thema),\n",
    "\"Which papers are associated with %s\" % (thema),\n",
    "\"What papers were associated with %s\" % (thema),\n",
    "\"What papers are associated with %s\" % (thema),\n",
    "]\n",
    "\n",
    "[\n",
    "\"How many papers have been published by %s\" % (name),\n",
    "\"How many papers are published by %s\" % (name),\n",
    "\"How many papers were published by %s\" % (name),\n",
    "\"How many papers have been published in %s\" % (conference),\n",
    "\"How many papers are published in %s\" % (conference),\n",
    "\"How many papers were published in %s\" % (conference),\n",
    "\"How many papers have been published since %s\" % (date),\n",
    "\"How many papers are published since %s\" % (date),\n",
    "\"How many papers were published since %s\" % (date),\n",
    "]\n",
    "[\n",
    "\"In which conferences has %s published?\" % (x),\n",
    "\"In what conferences has %s published?\" % (x),\n",
    "]\n",
    "\n",
    "[\n",
    "\"Which conferences since %s are most influential?\" % (date),\n",
    "\"What conferences since %s are most influential?\" % (date),\n",
    "\"Which conferences since %s have been most influential?\" % (date),\n",
    "\"What conferences since %s have been most influential?\" % (date),\n",
    "\"Which conferences since %s were most influential?\" % (date),\n",
    "\"What conferences since %s were most influential?\" % (date),\n",
    "]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Which conferences since 2009 are most influential?',\n",
       " 'What conferences since 2009 are most influential?',\n",
       " 'Which conferences since 2009 have been most influential?',\n",
       " 'What conferences since 2009 have been most influential?',\n",
       " 'Which conferences since 2009 were most influential?',\n",
       " 'What conferences since 2009 were most influential?']"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import re\n",
    "\n",
    "input_question = ''\n",
    "\n",
    "imrad_section_dict = {'Introduction' : ['(I|i)ntroduction'], \n",
    "                            'Methods' : ['method(s)?'],\n",
    "                            'Results' : ['result(s)?'],\n",
    "                            'Discussion' : ['discussion(s)?'] }\n",
    "\n",
    "for key in imrad_section_dict:\n",
    "    for template in imrad_section_dict[key]:\n",
    "        res = re.search(template, input_question)\n",
    "        if res != None:\n",
    "            print \"yes\""
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}